{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d2ae41",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-27T08:39:36.121466Z",
     "iopub.status.busy": "2025-10-27T08:39:36.121200Z",
     "iopub.status.idle": "2025-10-27T08:40:04.899579Z",
     "shell.execute_reply": "2025-10-27T08:40:04.898548Z"
    },
    "papermill": {
     "duration": 28.783187,
     "end_time": "2025-10-27T08:40:04.901066",
     "exception": false,
     "start_time": "2025-10-27T08:39:36.117879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting underthesea==6.8.4\r\n",
      "  Downloading underthesea-6.8.4-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from underthesea==6.8.4) (8.3.0)\r\n",
      "Collecting python-crfsuite>=0.9.6 (from underthesea==6.8.4)\r\n",
      "  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from underthesea==6.8.4) (3.9.1)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from underthesea==6.8.4) (4.67.1)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from underthesea==6.8.4) (2.32.5)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from underthesea==6.8.4) (1.5.2)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from underthesea==6.8.4) (1.2.2)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from underthesea==6.8.4) (6.0.3)\r\n",
      "Collecting underthesea-core==1.0.4 (from underthesea==6.8.4)\r\n",
      "  Downloading underthesea_core-1.0.4-cp311-cp311-manylinux2010_x86_64.whl.metadata (1.7 kB)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->underthesea==6.8.4) (2025.9.18)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea==6.8.4) (3.4.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea==6.8.4) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea==6.8.4) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea==6.8.4) (2025.8.3)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea==6.8.4) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea==6.8.4) (1.15.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea==6.8.4) (3.6.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea==6.8.4) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea==6.8.4) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea==6.8.4) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea==6.8.4) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea==6.8.4) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea==6.8.4) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->underthesea==6.8.4) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->underthesea==6.8.4) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn->underthesea==6.8.4) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn->underthesea==6.8.4) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn->underthesea==6.8.4) (2024.2.0)\r\n",
      "Downloading underthesea-6.8.4-py3-none-any.whl (20.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading underthesea_core-1.0.4-cp311-cp311-manylinux2010_x86_64.whl (657 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: underthesea-core, python-crfsuite, underthesea\r\n",
      "Successfully installed python-crfsuite-0.9.11 underthesea-6.8.4 underthesea-core-1.0.4\r\n",
      "Collecting scikit-learn==1.5.2\r\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.5.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (3.6.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.5.2) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.5.2) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.5->scikit-learn==1.5.2) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.5->scikit-learn==1.5.2) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.5->scikit-learn==1.5.2) (2024.2.0)\r\n",
      "Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: scikit-learn\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed scikit-learn-1.5.2\r\n",
      "Collecting pandas==2.2.2\r\n",
      "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas==2.2.2) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas==2.2.2) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas==2.2.2) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas==2.2.2) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas==2.2.2) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas==2.2.2) (2.4.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas==2.2.2) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas==2.2.2) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas==2.2.2) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas==2.2.2) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas==2.2.2) (2024.2.0)\r\n",
      "Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pandas\r\n",
      "  Attempting uninstall: pandas\r\n",
      "    Found existing installation: pandas 2.2.3\r\n",
      "    Uninstalling pandas-2.2.3:\r\n",
      "      Successfully uninstalled pandas-2.2.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed pandas-2.2.2\r\n",
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy==1.26.4) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy==1.26.4) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy==1.26.4) (2024.2.0)\r\n",
      "Collecting tqdm==4.66.5\r\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tqdm\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.67.1\r\n",
      "    Uninstalling tqdm-4.67.1:\r\n",
      "      Successfully uninstalled tqdm-4.67.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "tokenizers 0.21.2 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "transformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\r\n",
      "dataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "dataproc-spark-connect 0.8.3 requires tqdm>=4.67, but you have tqdm 4.66.5 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed tqdm-4.66.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip install underthesea==6.8.4\n",
    "!pip install scikit-learn==1.5.2\n",
    "!pip install pandas==2.2.2\n",
    "!pip install numpy==1.26.4\n",
    "!pip install tqdm==4.66.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221f42f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T08:40:04.910476Z",
     "iopub.status.busy": "2025-10-27T08:40:04.909808Z",
     "iopub.status.idle": "2025-10-27T08:40:20.409435Z",
     "shell.execute_reply": "2025-10-27T08:40:20.408806Z"
    },
    "papermill": {
     "duration": 15.505505,
     "end_time": "2025-10-27T08:40:20.410938",
     "exception": false,
     "start_time": "2025-10-27T08:40:04.905433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from underthesea import word_tokenize, pos_tag\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff3bd02b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T08:40:20.420807Z",
     "iopub.status.busy": "2025-10-27T08:40:20.420020Z",
     "iopub.status.idle": "2025-10-27T08:40:20.431422Z",
     "shell.execute_reply": "2025-10-27T08:40:20.430877Z"
    },
    "papermill": {
     "duration": 0.017321,
     "end_time": "2025-10-27T08:40:20.432461",
     "exception": false,
     "start_time": "2025-10-27T08:40:20.415140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)   # bỏ dấu câu\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "NEGATIVE_WORDS = [\n",
    "    \"không\", \"chẳng\", \"chưa\", \"chưa từng\", \"không bao giờ\", \"chẳng bao giờ\",\n",
    "    \"chưa bao giờ\", \"mãi mãi\", \"luôn luôn\", \"tất cả\", \"mọi người\", \"ai cũng\"\n",
    "]\n",
    "\n",
    "def neg_extreme_features(text):\n",
    "    tokens = word_tokenize(text, format=\"text\").split()\n",
    "    count = sum(1 for t in tokens if t in NEGATIVE_WORDS)\n",
    "    return count / max(1, len(tokens))\n",
    "\n",
    "EMO_LEXICON = [\n",
    "    \"tệ\", \"tồi\", \"vô dụng\", \"buồn\", \"sợ\", \"tức giận\", \"hối hận\", \"tuyệt vọng\",\n",
    "    \"vui\", \"hạnh phúc\", \"may mắn\", \"bi quan\", \"thất vọng\", \"đau khổ\", \"lo lắng\"\n",
    "]\n",
    "\n",
    "def emotion_features(text):\n",
    "    tokens = word_tokenize(text, format=\"text\").split()\n",
    "    emo_count = sum(1 for t in tokens if t in EMO_LEXICON)\n",
    "    return emo_count / max(1, len(tokens))\n",
    "\n",
    "def pos_ratio_features(text):\n",
    "    tagged = pos_tag(text)\n",
    "    total = len(tagged)\n",
    "    if total == 0:\n",
    "        return pd.Series({\"verb_ratio\": 0, \"adj_ratio\": 0, \"pron_ratio\": 0})\n",
    "    verbs = sum(1 for w, p in tagged if p.startswith(\"V\"))\n",
    "    adjs = sum(1 for w, p in tagged if p.startswith(\"A\"))\n",
    "    prons = sum(1 for w, p in tagged if w in [\"tôi\", \"mình\", \"ta\", \"chúng tôi\", \"bạn\", \"họ\"])\n",
    "    return pd.Series({\n",
    "        \"verb_ratio\": verbs / total,\n",
    "        \"adj_ratio\": adjs / total,\n",
    "        \"pron_ratio\": prons / total\n",
    "    })\n",
    "\n",
    "def length_features(text):\n",
    "    words = word_tokenize(text, format=\"text\").split()\n",
    "    return pd.Series({\n",
    "        \"word_count\": len(words),\n",
    "        \"avg_word_length\": np.mean([len(w) for w in words]) if words else 0\n",
    "    })\n",
    "\n",
    "def ngram_features(texts, ngram_range=(1,3), max_features=300):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        tokenizer=lambda x: word_tokenize(x, format=\"text\").split(),\n",
    "        ngram_range=ngram_range,\n",
    "        max_features=max_features\n",
    "    )\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    return pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "def extract_lexical_features(df, text_col=\"Original Text\"):\n",
    "    print(\"🔧 Tiền xử lý dữ liệu ...\")\n",
    "    df[\"clean_text\"] = df[text_col].progress_apply(preprocess_text)\n",
    "\n",
    "    print(\"🧩 Trích xuất các đặc trưng cơ bản ...\")\n",
    "    df[\"neg_ratio\"] = df[\"clean_text\"].progress_apply(neg_extreme_features)\n",
    "    df[\"emo_ratio\"] = df[\"clean_text\"].progress_apply(emotion_features)\n",
    "\n",
    "    pos_df = df[\"clean_text\"].progress_apply(pos_ratio_features)\n",
    "    len_df = df[\"clean_text\"].progress_apply(length_features)\n",
    "\n",
    "    df_features = pd.concat([df, pos_df, len_df], axis=1)\n",
    "\n",
    "    print(\"Sinh TF-IDF N-gram features ...\")\n",
    "    ngram_df = ngram_features(df_features[\"clean_text\"])\n",
    "\n",
    "    # Ghép tất cả\n",
    "    final_df = pd.concat([df_features.reset_index(drop=True), ngram_df.reset_index(drop=True)], axis=1)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dea17d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T08:40:20.441101Z",
     "iopub.status.busy": "2025-10-27T08:40:20.440640Z",
     "iopub.status.idle": "2025-10-27T08:40:20.622087Z",
     "shell.execute_reply": "2025-10-27T08:40:20.621375Z"
    },
    "papermill": {
     "duration": 0.187157,
     "end_time": "2025-10-27T08:40:20.623472",
     "exception": false,
     "start_time": "2025-10-27T08:40:20.436315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Emotional Reasoning</th>\n",
       "      <th>Overgeneralization</th>\n",
       "      <th>Should Statements</th>\n",
       "      <th>Personalization</th>\n",
       "      <th>Mental Filter</th>\n",
       "      <th>Disqualifying the Positive</th>\n",
       "      <th>Jumping to Conclusions</th>\n",
       "      <th>Labeling and Mislabeling</th>\n",
       "      <th>Magnification and Minimization</th>\n",
       "      <th>All-or-Nothing Thinking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cô ấy luôn có những hành động kỳ lạ, ví dụ như...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nếu bố mẹ tôi biết tôi đang vật lộn thế nào, h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trong năm thứ 4 và thứ 5 của sự nghiệp, tôi kh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tôi muốn bị ốm, và tôi biết điều đó thật khủng...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trước khi chúng tôi bắt đầu hẹn hò và trong nă...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Original Text  Label  \\\n",
       "0  Cô ấy luôn có những hành động kỳ lạ, ví dụ như...      0   \n",
       "1  Nếu bố mẹ tôi biết tôi đang vật lộn thế nào, h...      1   \n",
       "2  Trong năm thứ 4 và thứ 5 của sự nghiệp, tôi kh...      1   \n",
       "3  Tôi muốn bị ốm, và tôi biết điều đó thật khủng...      0   \n",
       "4  Trước khi chúng tôi bắt đầu hẹn hò và trong nă...      0   \n",
       "\n",
       "   Emotional Reasoning  Overgeneralization  Should Statements  \\\n",
       "0                    0                   0                  0   \n",
       "1                    0                   0                  0   \n",
       "2                    0                   0                  0   \n",
       "3                    0                   0                  0   \n",
       "4                    0                   0                  0   \n",
       "\n",
       "   Personalization  Mental Filter  Disqualifying the Positive  \\\n",
       "0                0              0                           0   \n",
       "1                0              0                           0   \n",
       "2                0              0                           0   \n",
       "3                0              0                           0   \n",
       "4                0              0                           0   \n",
       "\n",
       "   Jumping to Conclusions  Labeling and Mislabeling  \\\n",
       "0                       0                         0   \n",
       "1                       1                         0   \n",
       "2                       0                         0   \n",
       "3                       0                         0   \n",
       "4                       0                         0   \n",
       "\n",
       "   Magnification and Minimization  All-or-Nothing Thinking  \n",
       "0                               0                        0  \n",
       "1                               0                        0  \n",
       "2                               0                        1  \n",
       "3                               0                        0  \n",
       "4                               0                        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/cogdis-data/Combined_Data.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aef0140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T08:40:20.634973Z",
     "iopub.status.busy": "2025-10-27T08:40:20.634681Z",
     "iopub.status.idle": "2025-10-27T08:44:43.392300Z",
     "shell.execute_reply": "2025-10-27T08:44:43.391622Z"
    },
    "papermill": {
     "duration": 262.764107,
     "end_time": "2025-10-27T08:44:43.393694",
     "exception": false,
     "start_time": "2025-10-27T08:40:20.629587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Tiền xử lý dữ liệu ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20092/20092 [00:00<00:00, 49056.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧩 Trích xuất các đặc trưng cơ bản ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20092/20092 [00:34<00:00, 575.12it/s] \n",
      "100%|██████████| 20092/20092 [00:35<00:00, 570.72it/s] \n",
      "100%|██████████| 20092/20092 [01:50<00:00, 181.06it/s]\n",
      "100%|██████████| 20092/20092 [00:43<00:00, 458.26it/s] \n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sinh TF-IDF N-gram features ...\n"
     ]
    }
   ],
   "source": [
    "lexical_df = extract_lexical_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88162368",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T08:44:43.565801Z",
     "iopub.status.busy": "2025-10-27T08:44:43.565178Z",
     "iopub.status.idle": "2025-10-27T08:44:43.582895Z",
     "shell.execute_reply": "2025-10-27T08:44:43.582240Z"
    },
    "papermill": {
     "duration": 0.103807,
     "end_time": "2025-10-27T08:44:43.583969",
     "exception": false,
     "start_time": "2025-10-27T08:44:43.480162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Emotional Reasoning</th>\n",
       "      <th>Overgeneralization</th>\n",
       "      <th>Should Statements</th>\n",
       "      <th>Personalization</th>\n",
       "      <th>Mental Filter</th>\n",
       "      <th>Disqualifying the Positive</th>\n",
       "      <th>Jumping to Conclusions</th>\n",
       "      <th>Labeling and Mislabeling</th>\n",
       "      <th>...</th>\n",
       "      <th>đến</th>\n",
       "      <th>đều</th>\n",
       "      <th>để</th>\n",
       "      <th>đồng_nghiệp</th>\n",
       "      <th>đột_nhiên</th>\n",
       "      <th>đời</th>\n",
       "      <th>đủ</th>\n",
       "      <th>đứa</th>\n",
       "      <th>ấy</th>\n",
       "      <th>ở</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cô ấy luôn có những hành động kỳ lạ, ví dụ như...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.390131</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nếu bố mẹ tôi biết tôi đang vật lộn thế nào, h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trong năm thứ 4 và thứ 5 của sự nghiệp, tôi kh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tôi muốn bị ốm, và tôi biết điều đó thật khủng...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trước khi chúng tôi bắt đầu hẹn hò và trong nă...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148860</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Original Text  Label  \\\n",
       "0  Cô ấy luôn có những hành động kỳ lạ, ví dụ như...      0   \n",
       "1  Nếu bố mẹ tôi biết tôi đang vật lộn thế nào, h...      1   \n",
       "2  Trong năm thứ 4 và thứ 5 của sự nghiệp, tôi kh...      1   \n",
       "3  Tôi muốn bị ốm, và tôi biết điều đó thật khủng...      0   \n",
       "4  Trước khi chúng tôi bắt đầu hẹn hò và trong nă...      0   \n",
       "\n",
       "   Emotional Reasoning  Overgeneralization  Should Statements  \\\n",
       "0                    0                   0                  0   \n",
       "1                    0                   0                  0   \n",
       "2                    0                   0                  0   \n",
       "3                    0                   0                  0   \n",
       "4                    0                   0                  0   \n",
       "\n",
       "   Personalization  Mental Filter  Disqualifying the Positive  \\\n",
       "0                0              0                           0   \n",
       "1                0              0                           0   \n",
       "2                0              0                           0   \n",
       "3                0              0                           0   \n",
       "4                0              0                           0   \n",
       "\n",
       "   Jumping to Conclusions  Labeling and Mislabeling  ...       đến  đều   để  \\\n",
       "0                       0                         0  ...  0.000000  0.0  0.0   \n",
       "1                       1                         0  ...  0.000000  0.0  0.0   \n",
       "2                       0                         0  ...  0.099525  0.0  0.0   \n",
       "3                       0                         0  ...  0.000000  0.0  0.0   \n",
       "4                       0                         0  ...  0.134349  0.0  0.0   \n",
       "\n",
       "   đồng_nghiệp  đột_nhiên  đời   đủ  đứa        ấy    ở  \n",
       "0          0.0        0.0  0.0  0.0  0.0  0.390131  0.0  \n",
       "1          0.0        0.0  0.0  0.0  0.0  0.000000  0.0  \n",
       "2          0.0        0.0  0.0  0.0  0.0  0.000000  0.0  \n",
       "3          0.0        0.0  0.0  0.0  0.0  0.000000  0.0  \n",
       "4          0.0        0.0  0.0  0.0  0.0  0.148860  0.0  \n",
       "\n",
       "[5 rows x 320 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f3b9a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T08:44:43.852457Z",
     "iopub.status.busy": "2025-10-27T08:44:43.851887Z",
     "iopub.status.idle": "2025-10-27T08:44:47.921763Z",
     "shell.execute_reply": "2025-10-27T08:44:47.921156Z"
    },
    "papermill": {
     "duration": 4.156999,
     "end_time": "2025-10-27T08:44:47.923144",
     "exception": false,
     "start_time": "2025-10-27T08:44:43.766145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lexical_df.to_csv(\"lexical_features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8525910,
     "sourceId": 13516320,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 318.177003,
   "end_time": "2025-10-27T08:44:50.378436",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-27T08:39:32.201433",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
